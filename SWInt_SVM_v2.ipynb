{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train traj and labels loaded\n",
      "test traj and labels loaded\n"
     ]
    }
   ],
   "source": [
    "traj_train = np.load('traj_train.npy')\n",
    "labels_train = np.load('labels_train.npy')\n",
    "print 'train traj and labels loaded'\n",
    "\n",
    "traj_test = np.load('traj_test.npy')\n",
    "labels_test = np.load('labels_test.npy')\n",
    "print 'test traj and labels loaded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slotSize = 0\n",
    "clf_SVM = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __formatIntoFeatureVectorsAndLabels(traj, labels):\n",
    "    \"\"\"\n",
    "    Helper function. Converts the traj and labels into a feature vector matrix (design matrix) and a labels array, which is the proper format to input into the SVM.\n",
    "    :param traj: the demodded trajectories in an np array, with 3 indices: iqIndex, trajIndex, timeIndex\n",
    "    :param labels: the labels corresponding to the trajectories, 1d np array\n",
    "    :return: inputVectors (each feature vector is the I vector concatted with the Q vector) and labels_ggexc (labels for each trajectory, 0 for gg, 1 for exc)\n",
    "    \"\"\"\n",
    "    numTotalTraj = traj.shape[1]\n",
    "    numTimeBins = traj.shape[2]  # 5000 #num time bins per traj\n",
    "    \n",
    "    print '@@@ Start slotting; time: ', time.time() - timeStart\n",
    "    #: get inputVectors and labels_ggexc\n",
    "    ###\n",
    "    numSlots = numTimeBins / slotSize  # num slots per traj\n",
    "    \n",
    "#     #: obsolete code bcause it's too slow\n",
    "#     traj_slotted = np.zeros((2, numTotalTraj, numSlots))  # indices: iqIndex, labelIndex, trajIndex, slotIndex\n",
    "#     for trajIndex in np.arange(numTotalTraj):\n",
    "#         for j in np.arange(numSlots): #j is slotIndex\n",
    "#             traj_slotted[:, trajIndex, j] = traj[:, trajIndex, j*slotSize:j*slotSize+slotSize].mean(1)\n",
    "#             traj_slotted[1, trajIndex, j] = traj[1, trajIndex, j*slotSize:j*slotSize+slotSize].mean()\n",
    "    \n",
    "    traj_slotted = np.reshape(traj, (2, numTotalTraj, numSlots, slotSize)).mean(3)\n",
    "    \n",
    "    print '@@@ Finished slotting; time: ', time.time() - timeStart\n",
    "    \n",
    "#     print '@@@ Start concatting; time: ', time.time() - timeStart\n",
    "    inputVectors = np.concatenate((traj_slotted[0, :, :], traj_slotted[1, :, :]), axis=1) #sample vectors to input into the SVM;\n",
    "    labels_ggexc = np.array([0 if labels[i]==0 else 1 for i in np.arange(numTotalTraj) ]) # this groups gg as label 0, and exc as label 1\n",
    "#     print '@@@ Finished concatting; time: ', time.time() - timeStart\n",
    "    \n",
    "    return inputVectors, labels_ggexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __findFidelity(inputVectors, labels_ggexc):\n",
    "    \"\"\"\n",
    "    Helper function. Calculates the fidelity\n",
    "    :param inputVectors:\n",
    "    :param labels_ggexc:\n",
    "    :return: fidelity\n",
    "    \"\"\"\n",
    "    numTraj = inputVectors.shape[0]\n",
    "\n",
    "    #: find train fidelity\n",
    "    ###\n",
    "    labels_ggexc_predicted = clf_SVM.predict(inputVectors)\n",
    "\n",
    "    num_gg_exc = 0  # num of samples that are predicted 'gg' but are actually exc\n",
    "    num_exc_gg = 0  # num of samples that are predicted 'exc' but are actually gg\n",
    "    num_exc = 0  # total num of true exc sample\n",
    "    num_gg = 0  # total num of true exc sample\n",
    "\n",
    "    for i in np.arange(numTraj):\n",
    "        if labels_ggexc[i] == 1:\n",
    "            num_exc = num_exc + 1\n",
    "            if labels_ggexc_predicted[i] == 0:\n",
    "                num_gg_exc = num_gg_exc + 1\n",
    "        else:\n",
    "            num_gg = num_gg + 1\n",
    "            if labels_ggexc_predicted[i] == 1:\n",
    "                num_exc_gg = num_exc_gg + 1\n",
    "\n",
    "    prob_gg_exc = 1.0 * num_gg_exc / num_exc\n",
    "    prob_exc_gg = 1.0 * num_exc_gg / num_gg\n",
    "\n",
    "    fid_ggexc = 1 - (prob_gg_exc + prob_exc_gg) / 2\n",
    "\n",
    "    return fid_ggexc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print type(traj.shape[2] / slotSize)\n",
    "print traj.shape[2] / slotSize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ Start timing\n",
      "@@@ Start formatIntoFeatureVectorsAndLabels; time:  0.000982999801636\n",
      "@@@ Start slotting; time:  0.00145316123962\n",
      "@@@ Finished slotting; time:  1.67877006531\n",
      "@@@ Finished formatIntoFeatureVectorsAndLabels; time:  1.71913719177\n"
     ]
    }
   ],
   "source": [
    "### Testing _formatInto..\n",
    "\n",
    "\n",
    "timeStart = time.time()\n",
    "print '@@@ Start timing'\n",
    "\"\"\"\n",
    "Fits the SVM.\n",
    "\n",
    ":param traj:\n",
    ":param labels:\n",
    ":param slotSize: size (number of time units) of each slot, for performing slot weights integration\n",
    ":param tuneC: True if you want the method to tune C\n",
    ":param lstC: None if you want to use the default list of C's to sweep through for finding the optimal C; should be an np array or a list.\n",
    ":param validationFraction: fraction of the traj's to use as the validation set (tuning C happens on the validation set)\n",
    ":return: self\n",
    "\"\"\"\n",
    "traj = traj_train\n",
    "labels = labels_train\n",
    "slotSize=50 \n",
    "tuneC=False\n",
    "lstC=None\n",
    "validationFraction=0.25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numTotalTraj = traj.shape[1]\n",
    "\n",
    "print '@@@ Start formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "inputVectors, labels_ggexc = __formatIntoFeatureVectorsAndLabels(traj, labels)\n",
    "print '@@@ Finished formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 19.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "### testing\n",
    "\n",
    "test = np.random.rand(2,1000,10000)\n",
    "\n",
    "%timeit test.reshape(2, 100, 50, -1).mean(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 6)\n",
      "(2, 5, 2, 3)\n",
      "[[[ 6  0]\n",
      "  [ 7  8]\n",
      "  [ 8  6]\n",
      "  [ 9  6]\n",
      "  [10  6]]\n",
      "\n",
      " [[ 7  0]\n",
      "  [ 9  6]\n",
      "  [10  6]\n",
      "  [11  6]\n",
      "  [12  6]]]\n"
     ]
    }
   ],
   "source": [
    "### testing\n",
    "\n",
    "A = np.array([[[1,2,3,0,0,0],[1,2,4,1,4,3],[1,2,5,1,2,3],[1,2,6,1,2,3],[1,2,7,1,2,3]], \\\n",
    "              [[1,3,3,0,0,0],[2,3,4,1,2,3],[2,3,5,1,2,3],[2,3,6,1,2,3],[2,3,7,1,2,3]]])\n",
    "print A.shape\n",
    "A_reshaped = A.reshape((2,5,2,3))\n",
    "print A_reshaped.shape\n",
    "print A_reshaped.sum(3)\n",
    "\n",
    "# want: A_reshape = A.reshape((2, numTotalTraj, numTimeBins/slotSize, slotSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ Start timing\n",
      "@@@ Start formatIntoFeatureVectorsAndLabels; time:  0.00180101394653\n",
      "@@@ Start slotting; time:  0.00328087806702\n",
      "@@@ Finished slotting; time:  0.263383865356\n",
      "@@@ Finished formatIntoFeatureVectorsAndLabels; time:  0.313799858093\n",
      "Tuning C...\n",
      "On C = 1e-15 ; fid = 0.5\n",
      "On C = 1.88739182214e-15 ; fid = 0.5\n",
      "On C = 3.56224789026e-15 ; fid = 0.5\n",
      "On C = 6.7233575365e-15 ; fid = 0.5\n",
      "On C = 1.26896100317e-14 ; fid = 0.5\n",
      "On C = 2.39502661999e-14 ; fid = 0.5\n",
      "On C = 4.52035365636e-14 ; fid = 0.5\n",
      "On C = 8.53167852417e-14 ; fid = 0.5\n",
      "On C = 1.61026202756e-13 ; fid = 0.5\n",
      "On C = 3.03919538231e-13 ; fid = 0.5\n",
      "On C = 5.73615251045e-13 ; fid = 0.5\n",
      "On C = 1.08263673387e-12 ; fid = 0.502063584973\n",
      "On C = 2.04335971786e-12 ; fid = 0.520066428185\n",
      "On C = 3.85662042116e-12 ; fid = 0.589471415136\n",
      "On C = 7.27895384398e-12 ; fid = 0.721450603006\n",
      "On C = 1.37382379588e-11 ; fid = 0.827172607772\n",
      "On C = 2.5929437974e-11 ; fid = 0.87787222687\n",
      "On C = 4.89390091848e-11 ; fid = 0.897342612892\n",
      "On C = 9.23670857187e-11 ; fid = 0.906157122038\n",
      "On C = 1.7433288222e-10 ; fid = 0.909038966419\n",
      "On C = 3.29034456231e-10 ; fid = 0.909234563044\n",
      "On C = 6.21016941892e-10 ; fid = 0.906379339283\n",
      "On C = 1.17210229753e-09 ; fid = 0.904938417093\n",
      "On C = 2.21221629107e-09 ; fid = 0.902536880109\n",
      "On C = 4.17531893656e-09 ; fid = 0.902536880109\n",
      "On C = 7.88046281567e-09 ; fid = 0.902056572712\n",
      "On C = 1.48735210729e-08 ; fid = 0.901095957919\n",
      "On C = 2.80721620394e-08 ; fid = 0.901095957919\n",
      "On C = 5.29831690628e-08 ; fid = 0.900615650522\n",
      "On C = 1e-07 ; fid = 0.900615650522\n",
      "Chose optimal C =  3.29034456231e-10\n",
      "@@@ Start fitting the SVM; time:  10.6732478142\n",
      "@@@ Finished fitting the SVM; time:  10.9351189137\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJ/cxaBpF0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126e5fd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### \n",
    "\n",
    "timeStart = time.time()\n",
    "print '@@@ Start timing'\n",
    "\"\"\"\n",
    "Fits the SVM.\n",
    "\n",
    ":param traj:\n",
    ":param labels:\n",
    ":param slotSize: size (number of time units) of each slot, for performing slot weights integration\n",
    ":param tuneC: True if you want the method to tune C\n",
    ":param lstC: None if you want to use the default list of C's to sweep through for finding the optimal C; should be an np array or a list.\n",
    ":param validationFraction: fraction of the traj's to use as the validation set (tuning C happens on the validation set)\n",
    ":return: self\n",
    "\"\"\"\n",
    "traj = traj_train\n",
    "labels = labels_train\n",
    "slotSize=50 \n",
    "tuneC=True\n",
    "lstC=None\n",
    "validationFraction=0.25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numTotalTraj = traj.shape[1]\n",
    "\n",
    "print '@@@ Start formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "inputVectors, labels_ggexc = __formatIntoFeatureVectorsAndLabels(traj, labels)\n",
    "print '@@@ Finished formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "\n",
    "#: fit the clf_SVM, tune C if chosen to\n",
    "###\n",
    "inputVectors_shuffled, labels_ggexc_shuffled = shuffle(inputVectors, labels_ggexc, random_state=0)\n",
    "\n",
    "if tuneC == False:\n",
    "    clf_SVM = svm.LinearSVC(C=1.0)\n",
    "    clf_SVM.fit(inputVectors_shuffled, labels_ggexc_shuffled)\n",
    "else:\n",
    "    print 'Tuning C...'\n",
    "    lstFid = []\n",
    "    startIndex_validation = int(numTotalTraj * (1 - validationFraction))\n",
    "    if lstC is None:\n",
    "        lstC = 10 ** np.linspace(-15, -7, 30)\n",
    "    for C in lstC:\n",
    "        clf_SVM = svm.LinearSVC(C=C)\n",
    "        clf_SVM.fit(inputVectors_shuffled[0:startIndex_validation], labels_ggexc_shuffled[0:startIndex_validation])\n",
    "        temp_fid = __findFidelity(inputVectors_shuffled[startIndex_validation: ], labels_ggexc_shuffled[startIndex_validation: ])\n",
    "        print 'On C =', C, '; fid =', temp_fid\n",
    "        lstFid = lstFid + [temp_fid]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lstC, lstFid)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.title('Tuning C')\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Fidelity')\n",
    "\n",
    "    optimalC = lstC[np.argmax(lstFid)]\n",
    "    print 'Chose optimal C = ', optimalC\n",
    "    \n",
    "    print '@@@ Start fitting the SVM; time: ', time.time() - timeStart\n",
    "    clf_SVM = svm.LinearSVC(C=optimalC)\n",
    "    clf_SVM.fit(inputVectors_shuffled, labels_ggexc_shuffled)\n",
    "    print '@@@ Finished fitting the SVM; time: ', time.time() - timeStart\n",
    "    \n",
    "    \n",
    "# #: Tune slotSize\n",
    "\n",
    "# lstFid_tuneSlotSize = []\n",
    "# startIndex_validation = int(numTotalTraj * (1 - validationFraction))\n",
    "# lstSlotSize = np.array([5, 10, 20, 50, 100, 200, 500])\n",
    "# for s in lstSlotSize:\n",
    "#     slotSize = s\n",
    "#     print '@@@ !Start formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "#     inputVectors, labels_ggexc = __formatIntoFeatureVectorsAndLabels(traj, labels)\n",
    "#     print '@@@ !Finished formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "#     inputVectors_shuffled, labels_ggexc_shuffled = shuffle(inputVectors, labels_ggexc, random_state=0)\n",
    "#     clf_SVM = svm.LinearSVC(C=1.0)\n",
    "#     clf_SVM.fit(inputVectors_shuffled, labels_ggexc_shuffled)\n",
    "#     temp_fid = __findFidelity(inputVectors_shuffled[startIndex_validation: ], labels_ggexc_shuffled[startIndex_validation: ])\n",
    "#     print 'On slotSize =', slotSize, '; fid =', temp_fid\n",
    "#     lstFid_tuneSlotSize = lstFid_tuneSlotSize + [temp_fid]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(lstSlotSize, lstFid_tuneSlotSize)\n",
    "# plt.gca().set_xscale('log')\n",
    "# plt.title('Tuning slotSize')\n",
    "# plt.xlabel('slotSize')\n",
    "# plt.ylabel('Fidelity')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# print '@@@ Start finding train fidelity; time: ', time.time() - timeStart\n",
    "# fid_ggexc = __findFidelity(inputVectors_shuffled, labels_ggexc_shuffled)\n",
    "# print '@@@ Finished finding train fidelity; time: ', time.time() - timeStart\n",
    "\n",
    "# print 'train fid_ggexc: ', fid_ggexc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score (test fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ Start formatIntoFeatureVectorsAndLabels; time:  0.00570201873779\n",
      "@@@ Start slotting; time:  0.012708902359\n",
      "@@@ Finished slotting; time:  0.480344057083\n",
      "@@@ Finished formatIntoFeatureVectorsAndLabels; time:  0.492660999298\n",
      "test fid:  0.906666666667\n"
     ]
    }
   ],
   "source": [
    "timeStart = time.time()\n",
    "\n",
    "traj = traj_test\n",
    "labels= labels_test\n",
    "\n",
    "print '@@@ Start formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "inputVectors, labels_ggexc = __formatIntoFeatureVectorsAndLabels(traj, labels)\n",
    "print '@@@ Finished formatIntoFeatureVectorsAndLabels; time: ', time.time() - timeStart\n",
    "\n",
    "fid_ggexc = __findFidelity(inputVectors, labels_ggexc)\n",
    "\n",
    "print 'test fid: ', fid_ggexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'float'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demod(rawdata):\n",
    "    #: params for the rawdata\n",
    "    numTrajs = rawdata.shape[1] #5000 #num trajectories per label\n",
    "    duration = rawdata.shape[3] #5000 #time duration of entire track, in nanoseconds\n",
    "\n",
    "    #: params for demod\n",
    "    demod_freq =   0.047000000 #47 MHz = 0.047GHz\n",
    "    clock_freq = 1.000000000 # 1000MHz =1 GHz\n",
    "    rotation = 0\n",
    "    # demod_decay = None  #obsolete\n",
    "    start_window = 0 #units of time\n",
    "    end_window = duration #is this the correct end_window?\n",
    "\n",
    "    #: demod code\n",
    "    times = np.arange( int(start_window*clock_freq), int(end_window*clock_freq) ) * float(demod_freq/(clock_freq)) #unitless\n",
    "    demod_exp = np.exp(1j*(2*np.pi*times-rotation))\n",
    "    # if demod_decay is not None:   #obsolete\n",
    "    #     demod_exp *= np.exp(-1*times/(demod_decay*demod_freq))\n",
    "    demod_exp_I = np.array(np.real(demod_exp), dtype='float32')\n",
    "    demod_exp_Q = np.array(np.imag(demod_exp), dtype='float32')\n",
    "\n",
    "    #: traj_demod and traj_av_demod\n",
    "    traj_demod=np.zeros((2, 4, numTrajs, duration)) # indices are: iqIndex, labelIndex, trajIndex, timeIndex  ;  value is the i or q quadrature value\n",
    "    traj_av_demod=np.zeros((2, 4, duration)) # averages over the trajs; indices: iqIndex, labelIndex, timeIndex\n",
    "\n",
    "\n",
    "    for labelIndex in np.arange(4):\n",
    "        for trajIndex in np.arange(numTrajs):\n",
    "            traj_demod[0,labelIndex,trajIndex]=( (rawdata[0, trajIndex, labelIndex, :] - rawdata[0, trajIndex, labelIndex, :].mean())*demod_exp_I    -    (rawdata[1, trajIndex, labelIndex, :] - rawdata[1, trajIndex, labelIndex, :].mean())*demod_exp_Q)\n",
    "            traj_demod[1,labelIndex,trajIndex]=( (rawdata[0, trajIndex, labelIndex, :] - rawdata[0, trajIndex, labelIndex, :].mean())*demod_exp_Q    +    (rawdata[1, trajIndex, labelIndex, :] - rawdata[1, trajIndex, labelIndex, :].mean())*demod_exp_I)\n",
    "        traj_av_demod[0, labelIndex] = traj_demod[0, labelIndex,:,:].mean(0)\n",
    "        traj_av_demod[1, labelIndex] = traj_demod[1, labelIndex,:,:].mean(0)\n",
    "\n",
    "    #: preprocess the data a little\n",
    "    traj = np.concatenate((traj_demod[:,0,:,:], traj_demod[:,1,:,:], traj_demod[:,2,:,:], traj_demod[:,3,:,:]), axis=1)\n",
    "    labels = np.concatenate((np.zeros(numTrajs), np.ones(numTrajs), 2*np.ones(numTrajs), 3*np.ones(numTrajs)), axis=0)\n",
    "    return traj,labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
