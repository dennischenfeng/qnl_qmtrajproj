{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and getting rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw data:  (2, 5000, 4, 5000)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "\n",
    "#: get data from h5\n",
    "f = h5py.File('163223_Trajectories.hdf5','r')\n",
    "\n",
    "# to view the insides of the h5, use print f.keys()\n",
    "# print f['data']['Dependent0']\n",
    "rawdata = f['data']['Dependent0'][()] #this turns the h5data into a numpy file\n",
    "print('Shape of raw data: ', rawdata.shape)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing the rawdata into a proper format (feature vectors) to train our classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get traj_demod and traj_av_demod from rawdata; [traj_demod, traj_av_demod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#: params for the rawdata \n",
    "numTrajs = 5000 #num trajectories per label\n",
    "duration = 5000 #time duration of entire track, in nanoseconds\n",
    "\n",
    "#: params for demod\n",
    "demod_freq =   0.047000000 #47 MHz = 0.047GHz\n",
    "clock_freq = 1.000000000 # 1000MHz =1 GHz\n",
    "rotation = 0\n",
    "# demod_decay = None  #obsolete\n",
    "start_window = 0 #units of time\n",
    "end_window = duration #is this the correct end_window?\n",
    "\n",
    "\n",
    "\n",
    "#: demod code\n",
    "times = np.arange( int(start_window*clock_freq), int(end_window*clock_freq) ) * float(demod_freq/(clock_freq)) #unitless\n",
    "demod_exp = np.exp(1j*(2*np.pi*times-rotation))\n",
    "# if demod_decay is not None:   #obsolete\n",
    "#     demod_exp *= np.exp(-1*times/(demod_decay*demod_freq))\n",
    "demod_exp_I = np.array(np.real(demod_exp), dtype='float32')\n",
    "demod_exp_Q = np.array(np.imag(demod_exp), dtype='float32')\n",
    "\n",
    "\n",
    "#: traj_demod and traj_av_demod\n",
    "traj_demod=np.zeros((2, 4, numTrajs, duration)) # indices are: iqIndex, labelIndex, trajIndex, timeIndex  ;  value is the i or q quadrature value\n",
    "traj_av_demod=np.zeros((2, 4, duration)) # averages over the trajs; indices: iqIndex, labelIndex, timeIndex\n",
    "\n",
    "\n",
    "for labelIndex in np.arange(4):\n",
    "    for trajIndex in np.arange(numTrajs):\n",
    "        traj_demod[0,labelIndex,trajIndex]=( (rawdata[0, trajIndex, labelIndex, :] - rawdata[0, trajIndex, labelIndex, :].mean())*demod_exp_I    -    (rawdata[1, trajIndex, labelIndex, :] - rawdata[1, trajIndex, labelIndex, :].mean())*demod_exp_Q)\n",
    "        traj_demod[1,labelIndex,trajIndex]=( (rawdata[0, trajIndex, labelIndex, :] - rawdata[0, trajIndex, labelIndex, :].mean())*demod_exp_Q    +    (rawdata[1, trajIndex, labelIndex, :] - rawdata[1, trajIndex, labelIndex, :].mean())*demod_exp_I)\n",
    "    traj_av_demod[0, labelIndex] = traj_demod[0, labelIndex,:,:].mean(0)\n",
    "    traj_av_demod[1, labelIndex] = traj_demod[1, labelIndex,:,:].mean(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature vectors (slot-by-slot integrated form of I,Q quadratures) and labels; [inputData, labels01]; note: inputData only has gg and ee trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qnl/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/home/qnl/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/qnl/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/qnl/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "slotSize = 50 #please make duration divisible by slotSize\n",
    "numSlots = duration/slotSize # num slots per traj\n",
    "traj_demod_slotted = np.zeros((2, 4, numTrajs, numSlots)) # indices: iqIndex, labelIndex, trajIndex, slotIndex\n",
    "\n",
    "for labelIndex in np.arange(4):\n",
    "    for trajIndex in np.arange(numTrajs):\n",
    "        for j in np.arange(numSlots): #j is slotIndex\n",
    "            traj_demod_slotted[0,labelIndex, trajIndex, j] = traj_demod[0, labelIndex, trajIndex, j*slotSize:j*slotSize+slotSize].mean()\n",
    "            traj_demod_slotted[1,labelIndex, trajIndex, j] = traj_demod[1, labelIndex, trajIndex, j*slotSize:j*slotSize+slotSize].mean()\n",
    "            \n",
    "#: data inputted into the SVM ; feature vectors are I traj concatted with Q traj\n",
    "inputData = np.zeros([4*numTrajs, 2*numSlots]) # 4* numTrajs because 4 labels ; 2*numSlots because vector has both i and q trajs\n",
    "inputData[0:numTrajs, :] = np.hstack([traj_demod_slotted[0, 0, :, :], traj_demod_slotted[1, 0, :, :]])\n",
    "inputData[numTrajs:2*numTrajs, :] = np.hstack([traj_demod_slotted[0, 1, :, :], traj_demod_slotted[1, 1, :, :]])\n",
    "inputData[2*numTrajs:3*numTrajs, :] = np.hstack([traj_demod_slotted[0, 2, :, :], traj_demod_slotted[1, 2, :, :]])\n",
    "inputData[3*numTrajs:4*numTrajs, :] = np.hstack([traj_demod_slotted[0, 3, :, :], traj_demod_slotted[1, 3, :, :]])\n",
    "\n",
    "#: labels to input into SVM; NOT all 4 labels; its 0 if gg, 1 if {ee,ge,eg}\n",
    "labels01 = np.ones([4*numTrajs])\n",
    "labels01[0:numTrajs] = np.zeros([numTrajs])\n",
    "\n",
    "#: shuffle the data\n",
    "inputData, labels01 = shuffle(inputData, labels01, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fit with SVM, only use training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit LinearSVM v1 (LinearSVC()). First try to plot fidelity vs C (for hyperparam tuning); find optimal C (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C= 1e-15 , fidelity:  0.5\n",
      "For C= 1.4563484775e-15 , fidelity:  0.5\n",
      "For C= 2.12095088792e-15 , fidelity:  0.5\n",
      "For C= 3.08884359648e-15 , fidelity:  0.5\n",
      "For C= 4.49843266897e-15 , fidelity:  0.5\n",
      "For C= 6.5512855686e-15 , fidelity:  0.5\n",
      "For C= 9.5409547635e-15 , fidelity:  0.5\n",
      "For C= 1.38949549437e-14 , fidelity:  0.5\n",
      "For C= 2.02358964773e-14 , fidelity:  0.5\n",
      "For C= 2.94705170255e-14 , fidelity:  0.5\n",
      "For C= 4.29193426013e-14 , fidelity:  0.5004901960784314\n",
      "For C= 6.25055192527e-14 , fidelity:  0.5004901960784314\n",
      "For C= 9.10298177992e-14 , fidelity:  0.5004901960784314\n",
      "For C= 1.32571136559e-13 , fidelity:  0.5004901960784314\n",
      "For C= 1.93069772888e-13 , fidelity:  0.5004901960784314\n",
      "For C= 2.81176869797e-13 , fidelity:  0.5004901960784314\n",
      "For C= 4.09491506238e-13 , fidelity:  0.5004901960784314\n",
      "For C= 5.96362331659e-13 , fidelity:  0.5016252138439268\n",
      "For C= 8.68511373751e-13 , fidelity:  0.5029280168443215\n",
      "For C= 1.26485521686e-12 , fidelity:  0.5076621923937361\n",
      "For C= 1.84206996933e-12 , fidelity:  0.5208843268851164\n",
      "For C= 2.68269579528e-12 , fidelity:  0.5469930253980787\n",
      "For C= 3.90693993705e-12 , fidelity:  0.5923345176996972\n",
      "For C= 5.68986602902e-12 , fidelity:  0.6711244900644822\n",
      "For C= 8.28642772855e-12 , fidelity:  0.7557310172391104\n",
      "For C= 1.20679264064e-11 , fidelity:  0.8140742202921437\n",
      "For C= 1.75751062485e-11 , fidelity:  0.8582543755757337\n",
      "For C= 2.5595479227e-11 , fidelity:  0.8781056717989209\n",
      "For C= 3.72759372031e-11 , fidelity:  0.890656665350704\n",
      "For C= 5.42867543932e-11 , fidelity:  0.896525858665614\n",
      "For C= 7.90604321091e-11 , fidelity:  0.9022404263718911\n",
      "For C= 1.15139539933e-10 , fidelity:  0.9036978549809185\n",
      "For C= 1.67683293681e-10 , fidelity:  0.9041880510593499\n",
      "For C= 2.44205309455e-10 , fidelity:  0.9030530332938544\n",
      "For C= 3.55648030622e-10 , fidelity:  0.9029115673114884\n",
      "For C= 5.17947467923e-10 , fidelity:  0.9014541387024608\n",
      "For C= 7.54312006335e-10 , fidelity:  0.9014672983287275\n",
      "For C= 1.09854114199e-09 , fidelity:  0.900654691406764\n",
      "For C= 1.59985871961e-09 , fidelity:  0.8999967100934334\n",
      "For C= 2.32995181052e-09 , fidelity:  0.8996742992499013\n",
      "For C= 3.3932217719e-09 , fidelity:  0.8982037110146072\n",
      "For C= 4.94171336132e-09 , fidelity:  0.8972233188577444\n",
      "For C= 7.19685673001e-09 , fidelity:  0.8965653375444138\n",
      "For C= 1.04811313415e-08 , fidelity:  0.8963975523095145\n",
      "For C= 1.52641796718e-08 , fidelity:  0.8963975523095145\n",
      "For C= 2.22299648253e-08 , fidelity:  0.8959073562310831\n",
      "For C= 3.23745754282e-08 , fidelity:  0.8957395709961837\n",
      "For C= 4.71486636346e-08 , fidelity:  0.8954171601526517\n",
      "For C= 6.86648845004e-08 , fidelity:  0.8954171601526517\n",
      "For C= 1e-07 , fidelity:  0.8954171601526517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fa853579a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEOCAYAAACaQSCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhKKCoaIiISigiEiIqH8f3KPrbhpO/dFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8535c4ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#: params\n",
    "trainFraction = 4./5 #fraction of numTrajs to use as training set (validation set is part of the training set)\n",
    "validationFraction = 1./4 # what fraction OF TRAINING SET to use for validation\n",
    "lst_c = 10**np.linspace(-15, -7, 50) # list of C values (hyperparam for SVM) to train at\n",
    "\n",
    "\n",
    "startIndex_testData = int(numTrajs*trainFraction) * 4 # start index for test data ; multipled by 4 because the data set is 4 * numTraj long\n",
    "startIndex_validation = int(startIndex_testData * (1 - validationFraction))\n",
    "lst_fid = []\n",
    "\n",
    "for c in lst_c:\n",
    "    clf_linearSVM_v1 = svm.LinearSVC(C=c)\n",
    "    clf_linearSVM_v1.fit(inputData[0:startIndex_validation], labels01[0:startIndex_validation])\n",
    "    \n",
    "    #: find fidelity\n",
    "    \n",
    "    predicted_labels01 = clf_linearSVM_v1.predict(inputData[startIndex_validation:startIndex_testData])\n",
    "    p_0_1 = 0 # Prob(0|excited)\n",
    "    p_1_0 = 0 # Prob(1|gg)\n",
    "    num_0 = 0 # number of gg's\n",
    "    num_1 = 0 # number of excited states\n",
    "\n",
    "    for i in np.arange(len(predicted_labels01)):\n",
    "        if (labels01[startIndex_validation+i] == 1):\n",
    "            num_1 = num_1 + 1\n",
    "            if (predicted_labels01[i] == 0):\n",
    "                p_0_1 = p_0_1 + 1\n",
    "        elif (labels01[startIndex_validation+i] == 0):\n",
    "            num_0 = num_0 + 1\n",
    "            if (predicted_labels01[i] == 1):\n",
    "                p_1_0 = p_1_0 + 1\n",
    "\n",
    "    p_0_1 = 1.0 * p_0_1 / num_1\n",
    "    p_1_0 = 1.0 * p_1_0 / num_0\n",
    "    fid = 1 - (p_0_1 + p_1_0) / 2\n",
    "    lst_fid = lst_fid + [fid]\n",
    "    print('For C=', c, ', fidelity: ', fid)\n",
    "    \n",
    "plt.plot(lst_c, lst_fid)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Fidelity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit LinearSVM v2 (SVC(kernel='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #: params\n",
    "# trainFraction = 4./5 #fraction of numTrajs to use as training set (validation set is part of the training set)\n",
    "# validationFraction = 1./4 # what fraction OF TRAINING SET to use for validation\n",
    "# lst_c = 10**np.linspace(-13, -6, 20) # list of C values (hyperparam for SVM) to train at\n",
    "\n",
    "\n",
    "# startIndex_testData = int(numTrajs*trainFraction) * 4 # start index for test data ; multipled by 4 because the data set is 4 * numTraj long\n",
    "# startIndex_validation = int(startIndex_testData * (1 - validationFraction))\n",
    "# lst_fid = []\n",
    "\n",
    "# for c in lst_c:\n",
    "#     clf_linearSVM_v2 = svm.SVC(kernel='linear', C=c)\n",
    "#     clf_linearSVM_v2.fit(inputData[0:startIndex_validation], labels01[0:startIndex_validation])\n",
    "    \n",
    "#     #: find fidelity\n",
    "    \n",
    "#     predicted_labels01 = clf_linearSVM_v2.predict(inputData[startIndex_validation:startIndex_testData])\n",
    "#     p_0_1 = 0 # Prob(0|excited)\n",
    "#     p_1_0 = 0 # Prob(1|gg)\n",
    "#     num_0 = 0 # number of gg's\n",
    "#     num_1 = 0 # number of excited states\n",
    "\n",
    "#     for i in np.arange(len(predicted_labels01)):\n",
    "#         if (labels01[startIndex_validation+i] == 1):\n",
    "#             num_1 = num_1 + 1\n",
    "#             if (predicted_labels01[i] == 0):\n",
    "#                 p_0_1 = p_0_1 + 1\n",
    "#         elif (labels01[startIndex_validation+i] == 0):\n",
    "#             num_0 = num_0 + 1\n",
    "#             if (predicted_labels01[i] == 1):\n",
    "#                 p_1_0 = p_1_0 + 1\n",
    "\n",
    "#     p_0_1 = 1.0 * p_0_1 / num_1\n",
    "#     p_1_0 = 1.0 * p_1_0 / num_0\n",
    "#     fid = 1 - (p_0_1 + p_1_0) / 2\n",
    "#     lst_fid = lst_fid + [fid]\n",
    "#     print('For C=', c, ', fidelity: ', fid)\n",
    "    \n",
    "# plt.plot(lst_c, lst_fid)\n",
    "# plt.gca().set_xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Fidelity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RbfSVM (SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #: params\n",
    "# trainFraction = 4./5 #fraction of numTrajs to use as training set (validation set is part of the training set)\n",
    "# validationFraction = 1./4 # what fraction OF TRAINING SET to use for validation\n",
    "# lst_c = 10**np.linspace(-13, -6, 20) # list of C values (hyperparam for SVM) to train at\n",
    "\n",
    "\n",
    "# startIndex_testData = int(numTrajs*trainFraction) * 4 # start index for test data ; multipled by 4 because the data set is 4 * numTraj long\n",
    "# startIndex_validation = int(startIndex_testData * (1 - validationFraction))\n",
    "# lst_fid = []\n",
    "\n",
    "# for c in lst_c:\n",
    "#     clf_rbfSVM = svm.SVC(kernel='rbf', C=c)\n",
    "#     clf_rbfSVM.fit(inputData[0:startIndex_validation], labels01[0:startIndex_validation])\n",
    "    \n",
    "#     #: find fidelity\n",
    "    \n",
    "#     predicted_labels01 = clf_rbfSVM.predict(inputData[startIndex_validation:startIndex_testData])\n",
    "#     p_0_1 = 0 # Prob(0|excited)\n",
    "#     p_1_0 = 0 # Prob(1|gg)\n",
    "#     num_0 = 0 # number of gg's\n",
    "#     num_1 = 0 # number of excited states\n",
    "\n",
    "#     for i in np.arange(len(predicted_labels01)):\n",
    "#         if (labels01[startIndex_validation+i] == 1):\n",
    "#             num_1 = num_1 + 1\n",
    "#             if (predicted_labels01[i] == 0):\n",
    "#                 p_0_1 = p_0_1 + 1\n",
    "#         elif (labels01[startIndex_validation+i] == 0):\n",
    "#             num_0 = num_0 + 1\n",
    "#             if (predicted_labels01[i] == 1):\n",
    "#                 p_1_0 = p_1_0 + 1\n",
    "\n",
    "#     p_0_1 = 1.0 * p_0_1 / num_1\n",
    "#     p_1_0 = 1.0 * p_1_0 / num_0\n",
    "#     fid = 1 - (p_0_1 + p_1_0) / 2\n",
    "#     lst_fid = lst_fid + [fid]\n",
    "#     print('For C=', c, ', fidelity: ', fid)\n",
    "    \n",
    "# plt.plot(lst_c, lst_fid)\n",
    "# plt.gca().set_xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Fidelity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the clf's with the optimal c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_linearSVM_v1 = svm.LinearSVC(C=1.4e-10)\n",
    "clf_linearSVM_v1.fit(inputData[0:startIndex_testData], labels01[0:startIndex_testData])\n",
    "\n",
    "clf_linearSVM_v2 = svm.SVC(kernel='linear', C=1)\n",
    "clf_linearSVM_v2.fit(inputData[0:startIndex_testData], labels01[0:startIndex_testData])\n",
    "\n",
    "clf_rbfSVM = svm.SVC(kernel='rbf', C=1)\n",
    "clf_rbfSVM.fit(inputData[0:startIndex_testData], labels01[0:startIndex_testData])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate fidelity (on test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predicted_labels01 = clf_linearSVM_v1.predict(inputData[startIndex_testData: ])\n",
    "p_0_1 = 0 # Prob(0|excited)\n",
    "p_1_0 = 0 # Prob(1|gg)\n",
    "num_0 = 0 # number of gg's\n",
    "num_1 = 0 # number of excited states\n",
    "\n",
    "\n",
    "for i in np.arange(len(predicted_labels01)):\n",
    "    if (labels01[startIndex_testData+i] == 1):\n",
    "        num_1 = num_1 + 1\n",
    "        if (predicted_labels01[i] == 0):\n",
    "            p_0_1 = p_0_1 + 1\n",
    "    elif (labels01[startIndex_testData+i] == 0):\n",
    "        num_0 = num_0 + 1\n",
    "        if (predicted_labels01[i] == 1):\n",
    "            p_1_0 = p_1_0 + 1\n",
    "\n",
    "p_0_1 = 1.0 * p_0_1 / num_1\n",
    "p_1_0 = 1.0 * p_1_0 / num_0\n",
    "\n",
    "fid = 1 - (p_0_1 + p_1_0) / 2\n",
    "print('Fidelity: ', fid)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_linearSVM.score(inputData[startIndex_testData: ], labels01[startIndex_testData:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst_c.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
